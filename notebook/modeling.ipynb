{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             precision_recall_curve, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (FunctionTransformer, OneHotEncoder,\n",
    "                                   PolynomialFeatures, StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/NASA Near-Earth Objects-Train.csv'\n",
    "df = pd.read_csv(file,index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4568 entries, 2001981 to 54075323\n",
      "Data columns (total 14 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   absolute_magnitude_h               4568 non-null   float64\n",
      " 1   is_potentially_hazardous_asteroid  4568 non-null   bool   \n",
      " 2   is_sentry_object                   4568 non-null   bool   \n",
      " 3   kilometers_estimated_diameter_min  4568 non-null   float64\n",
      " 4   kilometers_estimated_diameter_max  4568 non-null   float64\n",
      " 5   orbit_class_type                   4568 non-null   object \n",
      " 6   perihelion_distance                4568 non-null   float64\n",
      " 7   aphelion_distance                  4568 non-null   float64\n",
      " 8   first_observation_date             4568 non-null   object \n",
      " 9   last_observation_date              4568 non-null   object \n",
      " 10  orbit_class_description            4568 non-null   object \n",
      " 11  first_observation_year             4568 non-null   int64  \n",
      " 12  last_observation_year              4568 non-null   int64  \n",
      " 13  is_collidable                      4568 non-null   bool   \n",
      "dtypes: bool(3), float64(5), int64(2), object(4)\n",
      "memory usage: 441.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_train = ['orbit_class_type','is_sentry_object','is_collidable']\n",
    "numeric_train = ['absolute_magnitude_h','kilometers_estimated_diameter_min','kilometers_estimated_diameter_max','perihelion_distance','first_observation_year','last_observation_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[cate_train + numeric_train]\n",
    "y = df['is_potentially_hazardous_asteroid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lượng dữ liệu dùng để train:  3288\n",
      "lượng dữ liệu dùng để validation:  823\n",
      "lượng dữ liệu dùng để test:  457\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "\n",
    "# 70% train , 15% validation, 15% test\n",
    "\n",
    "x_temp , x_test, y_temp, y_test = train_test_split(x,y,test_size=0.1,random_state=0)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_temp,y_temp,test_size=0.2,random_state=0)\n",
    "\n",
    "\n",
    "print (\"lượng dữ liệu dùng để train: \", x_train.shape[0])\n",
    "print (\"lượng dữ liệu dùng để validation: \", x_val.shape[0])\n",
    "print (\"lượng dữ liệu dùng để test: \", x_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sử dụng Pipeline để xây dựng mô hình\n",
    "- DÙng GridSearchCV để tìm ra mô hình tốt nhất\n",
    "- tạo mảng các mô hình cần thử (RandomForestClassifier, LogisticRegression)\n",
    "- PolynomialFeatures để tạo thêm các feature mới theo đa thức 1,2\n",
    "- Sampling data dùng SMOTE \n",
    "  <h3>Lưu mô hình lại vào file .pkl</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d =  1\n",
      "d =  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IE224-Phan tich du lieu\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d =  1\n",
      "d =  2\n",
      "{'model': 'LogisticRegression', 'degree': 1, 'accuracy': 0.8116646415552855, 'precision': 0.7883211678832117, 'recall': 0.826530612244898}\n",
      "__________________________-\n",
      "{'model': 'LogisticRegression', 'degree': 2, 'accuracy': 0.8444714459295262, 'precision': 0.851063829787234, 'recall': 0.8163265306122449}\n",
      "__________________________-\n",
      "{'model': 'RandomForestClassifier', 'degree': 1, 'accuracy': 0.8602673147023087, 'precision': 0.8673740053050398, 'recall': 0.8341836734693877}\n",
      "__________________________-\n",
      "{'model': 'RandomForestClassifier', 'degree': 2, 'accuracy': 0.8554070473876063, 'precision': 0.8719346049046321, 'recall': 0.8163265306122449}\n",
      "__________________________-\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dim = [1, 2]\n",
    "res = []\n",
    "best_models = {}  # Dictionary to store the best models\n",
    "\n",
    "# Models to evaluate\n",
    "Model = [\n",
    "    LogisticRegression(random_state=42),\n",
    "    RandomForestClassifier(random_state=42)\n",
    "]\n",
    "\n",
    "for model in Model:\n",
    "    for d in dim:\n",
    "        print(\"d = \", d)\n",
    "\n",
    "        # Preprocessors for numeric and categorical features\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', PolynomialFeatures(degree=d))\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        # Combine preprocessors\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, numeric_train),  # Replace `numeric_train` with actual columns\n",
    "                ('cat', categorical_transformer, cate_train)  # Replace `cate_train` with actual columns\n",
    "            ])\n",
    "\n",
    "        # Use imblearn's Pipeline to handle SMOTE\n",
    "        pipeline = ImbPipeline(\n",
    "            steps=[\n",
    "                ('preprocessor', preprocessor),  # Preprocessing pipeline\n",
    "                ('smote', SMOTE(random_state=42)),  # Handle imbalanced data\n",
    "                ('classifier', model)  # Current model\n",
    "            ])\n",
    "\n",
    "        # Define parameter grid\n",
    "        if model.__class__.__name__ == 'LogisticRegression':\n",
    "            param_grid = {\n",
    "                'classifier__C': [0.1, 1, 10],\n",
    "                'classifier__class_weight': ['balanced', {0: 1, 1: 2}]\n",
    "            }\n",
    "        elif model.__class__.__name__ == 'RandomForestClassifier':\n",
    "            param_grid = {\n",
    "                'classifier__n_estimators': [100, 200, 300],\n",
    "                'classifier__max_depth': [10, 15, 20],\n",
    "                'classifier__min_samples_split': [2, 5, 10],\n",
    "                'classifier__min_samples_leaf': [1, 2, 4],\n",
    "                'classifier__class_weight': ['balanced', {0: 1, 1: 2}]\n",
    "            }\n",
    "\n",
    "        # Perform grid search\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(x_train, y_train)\n",
    "\n",
    "        # Save the best model for this iteration\n",
    "        best_model_key = f\"{model.__class__.__name__}_degree_{d}\"\n",
    "        best_models[best_model_key] = grid_search.best_estimator_\n",
    "\n",
    "        # Save best model to a file\n",
    "        with open(f\"{best_model_key}.pkl\", 'wb') as f:\n",
    "            pickle.dump(grid_search.best_estimator_, f)\n",
    "\n",
    "        # Predictions and metrics\n",
    "        y_pred = grid_search.predict(x_val)\n",
    "        res.append({\n",
    "            'model': model.__class__.__name__,\n",
    "            'degree': d,\n",
    "            'accuracy': accuracy_score(y_val, y_pred),\n",
    "            'precision': precision_score(y_val, y_pred),\n",
    "            'recall': recall_score(y_val, y_pred)\n",
    "        })\n",
    "\n",
    "# Print results\n",
    "for r in res:\n",
    "    print(r)\n",
    "    print('__________________________-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Best Parameters: {'classifier__class_weight': {0: 1, 1: 2}, 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.74      0.82       253\n",
      "        True       0.74      0.91      0.82       204\n",
      "\n",
      "    accuracy                           0.82       457\n",
      "   macro avg       0.83      0.83      0.82       457\n",
      "weighted avg       0.83      0.82      0.82       457\n",
      "\n",
      "Recall Score: 0.9117647058823529\n",
      "Precision Score: 0.7380952380952381\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cate_train),  # Xử lý cột danh mục\n",
    "        ('num', StandardScaler(), numeric_train)  # Chuẩn hóa cột số\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 1. Tạo Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),  # Xử lý cột số và cột phân loại\n",
    "    ('smote', SMOTE(random_state=42)),  # Xử lý dữ liệu mất cân bằng\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Tạo đặc trưng đa thức\n",
    "    ('classifier', RandomForestClassifier(random_state=42))  # Random Forest\n",
    "])\n",
    "\n",
    "# 2. Cấu Hình GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],  # Số lượng cây\n",
    "    'classifier__max_depth': [10, 15, 20],  # Giới hạn độ sâu\n",
    "    'classifier__min_samples_split': [2, 5, 10],  # Mẫu tối thiểu để tách\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],  # Mẫu tối thiểu tại lá\n",
    "    'classifier__class_weight': ['balanced', {0: 1, 1: 2}]  # Cân bằng trọng số\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='recall',  # Đánh giá dựa trên recall\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 3. Huấn Luyện và Tìm Tham Số Tối Ưu\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# 4. In Kết Quả Tốt Nhất\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 5. Dự Đoán và Đánh Giá\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Recall Score:', recall_score(y_test, y_pred))\n",
    "print('Precision Score:', precision_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Best Parameters: {'classifier__class_weight': {0: 1, 1: 2}, 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 300}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.71      0.80       253\n",
      "        True       0.72      0.93      0.81       204\n",
      "\n",
      "    accuracy                           0.81       457\n",
      "   macro avg       0.82      0.82      0.81       457\n",
      "weighted avg       0.83      0.81      0.81       457\n",
      "\n",
      "Recall Score: 0.9313725490196079\n",
      "Precision Score: 0.7196969696969697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cate_train),  # Xử lý cột danh mục\n",
    "        ('num', StandardScaler(), numeric_train)  # Chuẩn hóa cột số\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 1. Tạo Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),  # Xử lý cột số và cột phân loại\n",
    "    ('smote', SMOTE(random_state=42)),  # Xử lý dữ liệu mất cân bằng\n",
    "    ('poly', PolynomialFeatures(degree=1, include_bias=False)),  # Tạo đặc trưng đa thức\n",
    "    ('classifier', RandomForestClassifier(random_state=42))  # Random Forest\n",
    "])\n",
    "\n",
    "# 2. Cấu Hình GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],  # Số lượng cây\n",
    "    'classifier__max_depth': [10, 15, 20],  # Giới hạn độ sâu\n",
    "    'classifier__min_samples_split': [2, 5, 10],  # Mẫu tối thiểu để tách\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],  # Mẫu tối thiểu tại lá\n",
    "    'classifier__class_weight': ['balanced', {0: 1, 1: 2}]  # Cân bằng trọng số\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='recall',  # Đánh giá dựa trên recall\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 3. Huấn Luyện và Tìm Tham Số Tối Ưu\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# 4. In Kết Quả Tốt Nhất\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 5. Dự Đoán và Đánh Giá\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Recall Score:', recall_score(y_test, y_pred))\n",
    "print('Precision Score:', precision_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.68      0.76       253\n",
      "        True       0.69      0.85      0.76       204\n",
      "\n",
      "    accuracy                           0.76       457\n",
      "   macro avg       0.77      0.77      0.76       457\n",
      "weighted avg       0.78      0.76      0.76       457\n",
      "\n",
      "Recall Score: 0.8529411764705882\n",
      "Precision Score: 0.6850393700787402\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cate_train),\n",
    "        ('num', MinMaxScaler(), numeric_train)\n",
    "    ]\n",
    ")\n",
    "\n",
    "x_train_processed = preprocessor.fit_transform(x_train)\n",
    "x_val_processed = preprocessor.transform(x_val)\n",
    "x_test_processed = preprocessor.transform(x_test)\n",
    "\n",
    "# 2. Oversampling với SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_processed, y_train)\n",
    "\n",
    "# 3. Undersampling với NearMiss\n",
    "nearmiss = NearMiss()\n",
    "x_train_resampled, y_train_resampled = nearmiss.fit_resample(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# 4. Thêm Polynomial Features\n",
    "poly = PolynomialFeatures(degree=1, include_bias=False)\n",
    "x_train_poly = poly.fit_transform(x_train_resampled)\n",
    "x_val_poly = poly.transform(x_val_processed)\n",
    "x_test_poly = poly.transform(x_test_processed)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Huấn luyện Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear', class_weight={0:3,1:4})\n",
    "model.fit(x_train_poly, y_train_resampled)\n",
    "\n",
    "# 6. Dự đoán và đánh giá\n",
    "y_pred = model.predict(x_test_poly)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Recall Score:', recall_score(y_test, y_pred))\n",
    "print('Precision Score:', precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
