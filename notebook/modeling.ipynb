{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             precision_recall_curve, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (FunctionTransformer, OneHotEncoder,\n",
    "                                   PolynomialFeatures, StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/NASA Near-Earth Objects-CleanbyThang.csv'\n",
    "df = pd.read_csv(file,index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23999 entries, 2001981 to 54073367\n",
      "Data columns (total 14 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   absolute_magnitude_h               23999 non-null  float64\n",
      " 1   is_potentially_hazardous_asteroid  23999 non-null  bool   \n",
      " 2   is_sentry_object                   23999 non-null  bool   \n",
      " 3   kilometers_estimated_diameter_min  23999 non-null  float64\n",
      " 4   kilometers_estimated_diameter_max  23999 non-null  float64\n",
      " 5   orbit_class_type                   23999 non-null  object \n",
      " 6   perihelion_distance                23999 non-null  float64\n",
      " 7   aphelion_distance                  23999 non-null  float64\n",
      " 8   first_observation_date             23999 non-null  object \n",
      " 9   last_observation_date              23999 non-null  object \n",
      " 10  orbit_class_description            23999 non-null  object \n",
      " 11  first_observation_year             23999 non-null  int64  \n",
      " 12  last_observation_year              23999 non-null  int64  \n",
      " 13  is_collidable                      23999 non-null  bool   \n",
      "dtypes: bool(3), float64(5), int64(2), object(4)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_train = ['orbit_class_type','is_sentry_object','is_collidable']\n",
    "numeric_train = ['absolute_magnitude_h','kilometers_estimated_diameter_min','kilometers_estimated_diameter_max','perihelion_distance','first_observation_year','last_observation_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[cate_train + numeric_train]\n",
    "y = df['is_potentially_hazardous_asteroid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lượng dữ liệu dùng để train:  17279\n",
      "lượng dữ liệu dùng để validation:  4320\n",
      "lượng dữ liệu dùng để test:  2400\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "\n",
    "# 70% train , 15% validation, 15% test\n",
    "\n",
    "x_temp , x_test, y_temp, y_test = train_test_split(x,y,test_size=0.1,random_state=0)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_temp,y_temp,test_size=0.2,random_state=0)\n",
    "\n",
    "\n",
    "print (\"lượng dữ liệu dùng để train: \", x_train.shape[0])\n",
    "print (\"lượng dữ liệu dùng để validation: \", x_val.shape[0])\n",
    "print (\"lượng dữ liệu dùng để test: \", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score:  1.0\n",
      "Validation Score: 0.9138888888888889\n",
      "Test Score: 0.9183333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.97      0.96      2189\n",
      "        True       0.56      0.36      0.43       211\n",
      "\n",
      "    accuracy                           0.92      2400\n",
      "   macro avg       0.75      0.66      0.69      2400\n",
      "weighted avg       0.91      0.92      0.91      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cate_train),  # Xử lý cột danh mục\n",
    "        ('num', StandardScaler(), numeric_train)  # Chuẩn hóa cột số\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "train_score = pipeline.score(x_train, y_train)\n",
    "val_score = pipeline.score(x_val, y_val)\n",
    "print(\"train_score: \", train_score)\n",
    "print(\"Validation Score:\", val_score)\n",
    "\n",
    "# tính toán độ chính xác trên tập test\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Score:\", test_score)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score:  0.9114532090977487\n",
      "Validation Score: 0.9074074074074074\n",
      "Test Score: 0.9116666666666666\n",
      "precision_score:  0.4888888888888889\n",
      "recall_score:  0.10426540284360189\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cate_train),  # Xử lý cột danh mục\n",
    "        ('num', StandardScaler(), numeric_train)  # Chuẩn hóa cột số\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "train_score = pipeline.score(x_train, y_train)\n",
    "val_score = pipeline.score(x_val, y_val)\n",
    "print(\"train_score: \", train_score)\n",
    "print(\"Validation Score:\", val_score)\n",
    "\n",
    "# tính toán độ chính xác trên tập test\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Score:\", test_score)\n",
    "print(\"precision_score: \", precision_score(y_test,y_pred))\n",
    "print(\"recall_score: \", recall_score(y_test,y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.913652410440419\n",
      "Validation Score: 0.9162037037037037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.98      0.95      2189\n",
      "        True       0.55      0.22      0.32       211\n",
      "\n",
      "    accuracy                           0.92      2400\n",
      "   macro avg       0.74      0.60      0.64      2400\n",
      "weighted avg       0.90      0.92      0.90      2400\n",
      "\n",
      "recall score:  0.22274881516587677\n",
      "precision score:  0.5465116279069767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import  cross_val_score\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cate_train),  # One-hot encoding cho các cột phân loại\n",
    "        ('num', StandardScaler(), numeric_train),  # Chuẩn hóa các cột số\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Tạo Pipeline cho mô hình Logistic Regression với Polynomial Features\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Thêm PolynomialFeatures vào pipeline\n",
    "    ('classifier', LogisticRegression(max_iter=1000,random_state=42,solver='liblinear'))  # Mô hình hồi quy logistic\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "train_score = pipeline.score(x_train, y_train)\n",
    "\n",
    "val_score = pipeline.score(x_val, y_val)\n",
    "\n",
    "print(\"Training Score:\", train_score)\n",
    "print(\"Validation Score:\", val_score)\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, pipeline.predict(x_test)\n",
    "))\n",
    "# tính với test \n",
    "y_pred = pipeline.predict(x_test)\n",
    "print('recall score: ', recall_score(y_test, y_pred))\n",
    "print('precision score: ', precision_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "val score 0.8993055555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cate_train),  # One-hot encoding cho các cột phân loại\n",
    "        ('num', StandardScaler(), numeric_train),  # Chuẩn hóa các cột số\n",
    "    ]\n",
    ")\n",
    "\n",
    "dt_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=2002))  # Mô hình cây quyết định\n",
    "])\n",
    "\n",
    "\n",
    "dt_pipeline.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "print('train score:', dt_pipeline.score(x_train,y_train))\n",
    "print('val score',dt_pipeline.score(x_val,y_val) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV scores: 0.9116267520233693\n",
      "Logistic Regression CV scores: 0.8936856977273946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import  cross_val_score\n",
    "\n",
    "log_reg_cv = LogisticRegression(solver='liblinear',max_iter=1000,random_state=42)\n",
    "dt_cv = DecisionTreeClassifier(random_state=2002)\n",
    "\n",
    "\n",
    "pipeline_cv_log_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', log_reg_cv)\n",
    "])\n",
    "\n",
    "pipeline_cv_dt = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', dt_cv)\n",
    "])\n",
    "\n",
    "lr_scores = cross_val_score(pipeline_cv_log_reg,x_train,y_train,cv=5)\n",
    "\n",
    "dt_scores = cross_val_score(pipeline_cv_dt,x_train,y_train)\n",
    "\n",
    "print('Logistic Regression CV scores:', lr_scores.mean())\n",
    "print('Logistic Regression CV scores:', dt_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8464031483303431\n",
      "Validation Score: 0.8513888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.84      0.91      2189\n",
      "        True       0.37      0.99      0.54       211\n",
      "\n",
      "    accuracy                           0.85      2400\n",
      "   macro avg       0.68      0.91      0.73      2400\n",
      "weighted avg       0.94      0.85      0.88      2400\n",
      "\n",
      "recall score:  0.985781990521327\n",
      "precision score:  0.37076648841354726\n"
     ]
    }
   ],
   "source": [
    "nm = NearMiss()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cate_train),  # One-hot encoding cho các cột phân loại\n",
    "        ('num', StandardScaler(), numeric_train),  # Chuẩn hóa các cột số\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Tạo Pipeline cho mô hình Logistic Regression với Polynomial Features\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Thêm PolynomialFeatures vào pipeline\n",
    "    ('classifier', LogisticRegression(max_iter=1000,random_state=42,solver='liblinear',class_weight='balanced'))  # Mô hình hồi quy logistic\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "train_score = pipeline.score(x_train, y_train)\n",
    "\n",
    "val_score = pipeline.score(x_val, y_val)\n",
    "\n",
    "print(\"Training Score:\", train_score)\n",
    "print(\"Validation Score:\", val_score)\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, pipeline.predict(x_test)\n",
    "))\n",
    "# tính với test \n",
    "y_pred = pipeline.predict(x_test)\n",
    "print('recall score: ', recall_score(y_test, y_pred))\n",
    "print('precision score: ', precision_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.83      0.90      2189\n",
      "        True       0.34      0.94      0.50       211\n",
      "\n",
      "    accuracy                           0.83      2400\n",
      "   macro avg       0.67      0.88      0.70      2400\n",
      "weighted avg       0.94      0.83      0.87      2400\n",
      "\n",
      "Recall Score: 0.9383886255924171\n",
      "Precision Score: 0.3407917383820998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cate_train),\n",
    "        ('num', MinMaxScaler(), numeric_train)\n",
    "    ]\n",
    ")\n",
    "\n",
    "x_train_processed = preprocessor.fit_transform(x_train)\n",
    "x_val_processed = preprocessor.transform(x_val)\n",
    "x_test_processed = preprocessor.transform(x_test)\n",
    "\n",
    "# 2. Oversampling với SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_processed, y_train)\n",
    "\n",
    "# 3. Undersampling với NearMiss\n",
    "nearmiss = NearMiss()\n",
    "x_train_resampled, y_train_resampled = nearmiss.fit_resample(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# 4. Thêm Polynomial Features\n",
    "poly = PolynomialFeatures(degree=1, include_bias=False)\n",
    "x_train_poly = poly.fit_transform(x_train_resampled)\n",
    "x_val_poly = poly.transform(x_val_processed)\n",
    "x_test_poly = poly.transform(x_test_processed)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Huấn luyện Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear', class_weight={0:3,1:4})\n",
    "model.fit(x_train_poly, y_train_resampled)\n",
    "\n",
    "# 6. Dự đoán và đánh giá\n",
    "y_pred = model.predict(x_test_poly)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Recall Score:', recall_score(y_test, y_pred))\n",
    "print('Precision Score:', precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.87      0.93      2189\n",
      "        True       0.41      0.95      0.57       211\n",
      "\n",
      "    accuracy                           0.88      2400\n",
      "   macro avg       0.70      0.91      0.75      2400\n",
      "weighted avg       0.94      0.88      0.90      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [10 ],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight={1:1,0:1},random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=3, scoring='recall', n_jobs=-1, verbose=2\n",
    ")\n",
    "grid_search.fit(x_train_poly, y_train_resampled)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_test_poly)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
